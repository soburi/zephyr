"""Utilities for validating devicetree macros against ``macros.bnf``.

This module provides helpers that parse the :file:`doc/build/dts/macros.bnf`
grammar and turn it into regular expressions.  These expressions are then
used to validate the macros generated by :file:`scripts/dts/gen_defines.py`.

The original tooling lives in the documentation tree of the upstream
project.  Only a very small subset is required for the tests in this kata
and the implementation below purposefully keeps the feature set limited to
what ``macros.bnf`` currently requires.  It is nonetheless written as a
stand-alone module so that pytest based tests can import it directly.

The :func:`validate_macros` helper is the main entry point.  It loads the
grammar, converts it to a compiled regular expression and finally checks the
macro names contained in a header file.  When executed as a script the
module behaves as a small CLI that exits with a non-zero status code if any
macro fails to match the grammar.
"""

from __future__ import annotations

from dataclasses import dataclass
import argparse
import pathlib
import re
from typing import Dict, Iterable, Iterator, List, Optional, Sequence


# ---------------------------------------------------------------------------
# ABNF parsing helpers


def _strip_comments(text: str) -> Iterator[str]:
    """Yield lines from *text* with ABNF comments removed.

    The grammar makes extensive use of ``;`` comments.  Everything from the
    first semicolon to the end of the line is ignored just like in standard
    ABNF.
    """

    for raw_line in text.splitlines():
        line, *_ = raw_line.split(";", 1)
        stripped = line.strip()
        if stripped:
            yield stripped


def _collect_rule_text(lines: Iterable[str]) -> Dict[str, List[str]]:
    """Collect the textual representation of ABNF rules.

    The function understands the ``=`` and ``=/`` operators as well as
    continuation lines.  The returned mapping associates each rule with a
    list of textual alternatives.
    """

    rules: Dict[str, List[str]] = {}
    current_rule: Optional[str] = None
    current_idx: Optional[int] = None

    rule_re = re.compile(r"^(?P<name>[A-Za-z0-9_-]+)\s*=/?\s*(?P<body>.*)$")

    for line in lines:
        match = rule_re.match(line)
        if match:
            current_rule = match.group("name")
            current_idx = None
            body = match.group("body").strip()
            rules.setdefault(current_rule, [])
            rules[current_rule].append(body)
            current_idx = len(rules[current_rule]) - 1
            continue

        if current_rule is None or current_idx is None:
            raise ValueError(f"Dangling grammar text: {line!r}")

        continuation = line.strip()
        rules[current_rule][current_idx] += " " + continuation

    return rules


# ---------------------------------------------------------------------------
# Expression tree


@dataclass
class Expr:
    def to_regex(self) -> str:
        raise NotImplementedError


@dataclass
class Literal(Expr):
    value: str

    def to_regex(self) -> str:  # pragma: no cover - trivial
        return re.escape(self.value)


@dataclass
class Range(Expr):
    lower: str
    upper: str

    def to_regex(self) -> str:  # pragma: no cover - trivial
        return f"[{self.lower}-{self.upper}]"


@dataclass
class RuleRef(Expr):
    name: str
    cache: Dict[str, "Expr"]

    def to_regex(self) -> str:
        return build_regex(self.name, self.cache)


@dataclass
class SequenceExpr(Expr):
    parts: Sequence[Expr]

    def to_regex(self) -> str:
        return "".join(part.to_regex() for part in self.parts)


@dataclass
class ChoiceExpr(Expr):
    options: Sequence[Expr]

    def to_regex(self) -> str:
        joined = "|".join(option.to_regex() for option in self.options)
        return f"(?:{joined})"


@dataclass
class OptionalExpr(Expr):
    expr: Expr

    def to_regex(self) -> str:
        return f"(?:{self.expr.to_regex()})?"


@dataclass
class RepeatExpr(Expr):
    expr: Expr
    min_count: int
    max_count: Optional[int]

    def to_regex(self) -> str:
        pattern = f"(?:{self.expr.to_regex()})"
        if self.max_count is None:
            if self.min_count == 0:
                suffix = "*"
            elif self.min_count == 1:
                suffix = "+"
            else:
                suffix = f"{{{self.min_count},}}"
        elif self.min_count == self.max_count:
            suffix = f"{{{self.min_count}}}"
        else:
            suffix = f"{{{self.min_count},{self.max_count}}}"
        return pattern + suffix


class GrammarParser:
    """Minimal ABNF parser tailored to ``macros.bnf``."""

    def __init__(self, text: str, cache: Dict[str, Expr]):
        self.text = text
        self.pos = 0
        self.cache = cache

    def parse(self) -> Expr:
        expr = self._parse_alternation()
        self._skip_ws()
        if self.pos != len(self.text):  # pragma: no cover - defensive
            raise ValueError(f"Unexpected trailing text: {self.text[self.pos:]}" )
        return expr

    # Parsing utilities -------------------------------------------------

    def _skip_ws(self) -> None:
        while self.pos < len(self.text) and self.text[self.pos].isspace():
            self.pos += 1

    def _peek(self) -> Optional[str]:
        if self.pos >= len(self.text):
            return None
        return self.text[self.pos]

    def _consume(self, expected: str) -> None:
        if not self.text.startswith(expected, self.pos):  # pragma: no cover - defensive
            raise ValueError(f"Expected {expected!r}")
        self.pos += len(expected)

    # Grammar -----------------------------------------------------------

    def _parse_alternation(self) -> Expr:
        options = [self._parse_concatenation()]
        self._skip_ws()
        while self._peek() == "/":
            self.pos += 1
            options.append(self._parse_concatenation())
            self._skip_ws()
        if len(options) == 1:
            return options[0]
        return ChoiceExpr(options)

    def _parse_concatenation(self) -> Expr:
        parts: List[Expr] = []
        while True:
            self._skip_ws()
            token = self._peek()
            if token is None or token in ")/]":
                break
            parts.append(self._parse_repetition())
        if not parts:
            return Literal("")
        if len(parts) == 1:
            return parts[0]
        return SequenceExpr(parts)

    def _parse_repetition(self) -> Expr:
        self._skip_ws()
        start = self.pos
        min_count = max_count = None

        while self._peek() and self._peek().isdigit():
            self.pos += 1

        if self._peek() == "*":
            number = self.text[start:self.pos]
            min_count = int(number) if number else 0
            self.pos += 1
            start = self.pos
            while self._peek() and self._peek().isdigit():
                self.pos += 1
            number = self.text[start:self.pos]
            max_count = int(number) if number else None
        else:
            self.pos = start

        element = self._parse_element()

        if min_count is None:
            return element
        return RepeatExpr(element, min_count, max_count)

    def _parse_element(self) -> Expr:
        self._skip_ws()
        char = self._peek()
        if char is None:
            raise ValueError("Unexpected end of expression")

        if char == "(":
            self.pos += 1
            expr = self._parse_alternation()
            self._skip_ws()
            self._consume(")")
            return expr

        if char == "[":
            self.pos += 1
            expr = self._parse_alternation()
            self._skip_ws()
            self._consume("]")
            return OptionalExpr(expr)

        if char == '"':
            return self._parse_quoted()

        if char == "%":
            return self._parse_percent_encoded()

        return self._parse_identifier()

    def _parse_quoted(self) -> Expr:
        self.pos += 1
        start = self.pos
        while self._peek() not in {'"', None}:  # pragma: no branch - simple loop
            self.pos += 1
        value = self.text[start:self.pos]
        self._consume('"')
        return Literal(value)

    def _parse_percent_encoded(self) -> Expr:
        if self.text.startswith("%s\"", self.pos):
            self.pos += 3
            start = self.pos
            while self._peek() not in {'"', None}:  # pragma: no branch - simple loop
                self.pos += 1
            value = self.text[start:self.pos]
            self._consume('"')
            return Literal(value)

        if self.text.startswith("%x", self.pos):
            self.pos += 2
            start = self.pos
            while self._peek() not in {"-", None}:
                self.pos += 1
            lower = chr(int(self.text[start:self.pos], 16))
            self._consume("-")
            start = self.pos
            while self._peek() and self._peek().isalnum():
                self.pos += 1
            upper = chr(int(self.text[start:self.pos], 16))
            return Range(lower, upper)

        raise ValueError(f"Unsupported percent-encoded literal: {self.text[self.pos:]}" )

    def _parse_identifier(self) -> Expr:
        start = self.pos
        while self._peek() and re.match(r"[A-Za-z0-9_-]", self._peek()):
            self.pos += 1
        identifier = self.text[start:self.pos]
        if not identifier:
            raise ValueError("Expected identifier")
        return RuleRef(identifier, self.cache)


def build_regex(rule: str, cache: Dict[str, Expr]) -> str:
    """Compile *rule* to a regular expression."""

    expr = cache.get(rule)
    if expr is None:
        raise KeyError(f"Unknown rule: {rule}")
    return expr.to_regex()


def _prepare_expression_tree(grammar_text: str) -> Dict[str, Expr]:
    lines = _strip_comments(grammar_text)
    raw_rules = _collect_rule_text(lines)

    # Inject the standard ABNF ``DIGIT`` rule which is not redefined in the
    # grammar file but used liberally.
    raw_rules.setdefault("DIGIT", ["%x30-39"])

    cache: Dict[str, Expr] = {}
    for name, bodies in raw_rules.items():
        # Concatenate alternatives into a single choice expression.
        options = [GrammarParser(body, cache).parse() for body in bodies]
        if len(options) == 1:
            cache[name] = options[0]
        else:
            cache[name] = ChoiceExpr(options)

    return cache


def compile_grammar(grammar_text: str) -> re.Pattern[str]:
    """Compile ``macros.bnf`` into a ``re.Pattern`` for ``dt-macro``."""

    cache = _prepare_expression_tree(grammar_text)
    regex = build_regex("dt-macro", cache)
    return re.compile(f"^(?:{regex})$")


# ---------------------------------------------------------------------------
# Macro helpers
def iter_macro_names(header_text: str) -> Iterator[str]:
    """Yield the macro identifiers from *header_text*.

    The helper ignores function like parameter lists and only yields the raw
    identifier part so that it can be matched against the grammar.
    """

    for line in header_text.splitlines():
        line = line.strip()
        if not line.startswith("#define DT_"):
            continue
        tokens = line.split()
        if len(tokens) < 2:
            continue
        identifier = tokens[1]
        # Drop function-like parameter lists.
        if "(" in identifier:
            identifier = identifier.split("(", 1)[0]
        yield identifier


# ---------------------------------------------------------------------------
# Public API


def validate_macros(header_text: str, grammar_text: str) -> List[str]:
    """Return a list of macros not covered by the grammar."""

    pattern = compile_grammar(grammar_text)
    invalid = [macro for macro in iter_macro_names(header_text)
               if not pattern.fullmatch(macro)]
    return invalid


def _cli(argv: Optional[Sequence[str]] = None) -> int:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("header", type=pathlib.Path, help="Header to validate")
    parser.add_argument("grammar", type=pathlib.Path, help="ABNF grammar file")
    args = parser.parse_args(argv)

    invalid = validate_macros(args.header.read_text(encoding="utf-8"),
                              args.grammar.read_text(encoding="utf-8"))
    if invalid:
        for macro in invalid:
            print(macro)
        return 1
    return 0


def main() -> None:  # pragma: no cover - CLI thin wrapper
    raise SystemExit(_cli())


if __name__ == "__main__":  # pragma: no cover
    main()
